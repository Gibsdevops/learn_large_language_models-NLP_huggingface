{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM50rGc5MhvCTgaFvLsgjAD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gibsdevops/learn_large_language_models-NLP_huggingface/blob/main/saving_loading_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a transformer"
      ],
      "metadata": {
        "id": "bL5c5zDwSHSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the tokenizer, the from_pretrained() method will download and cache the model data from the Hugging Face Hub. As mentioned previously, the checkpoint name corresponds to a specific model architecture and weights, in this case a BERT model with a basic architecture (12 layers, 768 hidden size, 12 attention heads) and cased inputs (meaning that the uppercase/lowercase distinction is important)."
      ],
      "metadata": {
        "id": "dS7VJbCOSX3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s begin by examining what happens when we instantiate an AutoModel:\n",
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "PwBbQwoFQ8zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sExumh5bPwGl"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if u know the class where to get the mode from there's no need to use he AutoModel\n",
        "\n",
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "opX1HRWcQ5T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading and saving\n",
        "\n",
        "Saving a model is as simple as saving a tokenizer. In fact, the models actually have the same save_pretrained() method, which saves the model’s weights and architecture configuration:"
      ],
      "metadata": {
        "id": "qs599GPFT0Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"directory_on_my_computer\")"
      ],
      "metadata": {
        "id": "0i5TXGm_Tr9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls directory_on_my_computer\n",
        "\n"
      ],
      "metadata": {
        "id": "WYx9U9bwUDi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resuinf the saved model\n",
        "\n",
        "from transformers import AutoModel\n",
        "\n",
        "model_2 = AutoModel.from_pretrained(\"directory_on_my_computer\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HwxXjAtTUWzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loggign in the hugging face using the notebook\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "1-XnSuvhWYt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.push_to_hub(\"my-awesome-model\")"
      ],
      "metadata": {
        "id": "wTsnf19XWntV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-MoLHFErWqv3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}